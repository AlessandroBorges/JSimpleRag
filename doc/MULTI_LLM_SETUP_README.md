# Setup de M√∫ltiplos Provedores LLM - Quick Start

**Vers√£o**: 1.0
**Data**: 2025-10-13
**Status**: ‚úÖ Pronto para Uso

---

## üéØ O Que Foi Implementado

Sistema completo de gerenciamento de m√∫ltiplos provedores LLM com:

‚úÖ **Configura√ß√£o Prim√°ria e Secund√°ria**
‚úÖ **6 Estrat√©gias de Uso Diferentes**
‚úÖ **Failover Autom√°tico**
‚úÖ **Load Balancing**
‚úÖ **Estat√≠sticas e Monitoramento**
‚úÖ **Tratamento de Erros Robusto**

---

## üöÄ Quick Start

### 1. Configura√ß√£o B√°sica (Sem Secund√°rio)

**Arquivo**: `.env` ou `application.properties`

```properties
# Apenas provedor prim√°rio (LM Studio local)
llmservice.provider.name=LM_STUDIO
llmservice.provider.embedding.model=text-embedding-nomic-embed-text-v1.5@q8_0
llmservice.provider.embedding.dimension=768
llmservice.provider.api.url=http://localhost:1234/v1

# Secund√°rio desabilitado
llmservice.provider2.enabled=false
llmservice.strategy=PRIMARY_ONLY
```

### 2. Configura√ß√£o com Backup (Recomendado para Produ√ß√£o)

```properties
# Primary: LM Studio local (r√°pido, gr√°tis)
llmservice.provider.name=LM_STUDIO
llmservice.provider.embedding.model=text-embedding-nomic-embed-text-v1.5@q8_0
llmservice.provider.embedding.dimension=768
llmservice.provider.api.url=http://localhost:1234/v1

# Secondary: OpenAI backup (confi√°vel, pago)
llmservice.provider2.enabled=true
llmservice.provider2.name=OPENAI
llmservice.provider2.embedding.model=text-embedding-ada-002
llmservice.provider2.embedding.dimension=1536
llmservice.provider2.api.key=${OPENAI_API_KEY}

# Estrat√©gia: Failover autom√°tico
llmservice.strategy=FAILOVER
llmservice.failover.max-retries=3
```

### 3. Uso no C√≥digo

```java
@Service
public class MyService {

    @Autowired
    private LLMServiceManager llmManager;

    public void processDocument(String text) {
        // Gera embedding com failover autom√°tico
        float[] embedding = llmManager.generateEmbedding(text);

        // Use o embedding...
    }
}
```

**Pronto!** O sistema automaticamente:
- Usa o provedor prim√°rio (LM Studio)
- Se falhar, usa o secund√°rio (OpenAI)
- Registra estat√≠sticas
- Trata erros

---

## üìã Arquivos Criados

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `MultiLLMServiceConfig.java` | Configura√ß√£o Spring para m√∫ltiplos provedores |
| `LLMServiceManager.java` | Gerenciador com estrat√©gias e failover |
| `LLMServiceStrategy.java` | Enum com 6 estrat√©gias dispon√≠veis |
| `LLMServiceException.java` | Exce√ß√µes tipadas para tratamento de erros |
| `LLMServiceManagerTest.java` | Testes unit√°rios completos |
| `MULTI_LLM_PROVIDER_GUIDE.md` | Documenta√ß√£o detalhada |
| `.env.example` | Template de configura√ß√£o |

---

## üé® Estrat√©gias Dispon√≠veis

### 1. PRIMARY_ONLY
Usa apenas o prim√°rio. Ideal para desenvolvimento.

```properties
llmservice.strategy=PRIMARY_ONLY
```

### 2. FAILOVER (Recomendado)
Prim√°rio com backup autom√°tico. Ideal para produ√ß√£o.

```properties
llmservice.strategy=FAILOVER
```

**Fluxo**:
```
Request ‚Üí Primary
  ‚îú‚îÄ ‚úÖ Success ‚Üí Return
  ‚îî‚îÄ ‚ùå Failure ‚Üí Secondary
      ‚îú‚îÄ ‚úÖ Success ‚Üí Return
      ‚îî‚îÄ ‚ùå Failure ‚Üí Exception
```

### 3. ROUND_ROBIN
Distribui carga alternadamente.

```properties
llmservice.strategy=ROUND_ROBIN
```

### 4. SPECIALIZED
Embeddings no prim√°rio, completions no secund√°rio.

```properties
llmservice.strategy=SPECIALIZED
```

### 5. DUAL_VERIFICATION
Executa em ambos e compara resultados (QA).

```properties
llmservice.strategy=DUAL_VERIFICATION
```

### 6. SMART_ROUTING
Roteia baseado na complexidade da query.

```properties
llmservice.strategy=SMART_ROUTING
```

---

## üìä Monitoramento

### Endpoint de Estat√≠sticas

```java
@RestController
public class MonitoringController {

    @Autowired
    private LLMServiceManager llmManager;

    @GetMapping("/api/llm/stats")
    public LLMServiceStats getStats() {
        return llmManager.getStatistics();
    }
}
```

**Resposta**:
```json
{
  "providerCount": 2,
  "primaryRequests": 1250,
  "secondaryRequests": 42,
  "failoverEvents": 15,
  "totalRequests": 1292,
  "secondaryUsagePercentage": 3.2
}
```

### Health Check

```java
boolean primaryHealthy = llmManager.isProviderHealthy(0);
boolean secondaryHealthy = llmManager.isProviderHealthy(1);
```

---

## üîß Exemplos de Configura√ß√£o

### Desenvolvimento (Gr√°tis)

```properties
llmservice.provider.name=LM_STUDIO
llmservice.provider2.enabled=false
llmservice.strategy=PRIMARY_ONLY
```

### Produ√ß√£o (Alta Disponibilidade)

```properties
# Primary: LM Studio
llmservice.provider.name=LM_STUDIO
llmservice.provider.api.url=http://llm-server:1234/v1

# Secondary: OpenAI
llmservice.provider2.enabled=true
llmservice.provider2.name=OPENAI
llmservice.provider2.api.key=${OPENAI_API_KEY}

llmservice.strategy=FAILOVER
llmservice.failover.max-retries=3
```

### H√≠brido Local + Cloud

```properties
# Primary: Local (embeddings)
llmservice.provider.name=OLLAMA
llmservice.provider.embedding.model=nomic-embed-text

# Secondary: Cloud (completions)
llmservice.provider2.enabled=true
llmservice.provider2.name=OPENAI
llmservice.provider2.llm.models=gpt-4

llmservice.strategy=SPECIALIZED
```

---

## üêõ Troubleshooting

### Problema: Secondary n√£o √© usado

**Causa**: N√£o est√° habilitado

**Solu√ß√£o**:
```properties
llmservice.provider2.enabled=true  # ‚Üê Certifique-se que est√° true
```

### Problema: Custos muito altos

**Causa**: Estrat√©gia DUAL_VERIFICATION ou ROUND_ROBIN

**Solu√ß√£o**: Mude para FAILOVER ou SMART_ROUTING
```properties
llmservice.strategy=FAILOVER  # S√≥ usa secondary em falhas
```

### Problema: Primary sempre falha

**Verificar**:
1. LM Studio est√° rodando?
2. URL est√° correta?
3. Modelo est√° carregado?

```bash
# Teste manual
curl http://localhost:1234/v1/models
```

---

## üìö Documenta√ß√£o Completa

Consulte:
- **`MULTI_LLM_PROVIDER_GUIDE.md`** - Guia completo com todos os detalhes
- **`LLM_SERVICE_CONFIGURATION.md`** - Configura√ß√£o b√°sica (single provider)

---

## üß™ Testes

```bash
# Teste de configura√ß√£o
./mvnw test -Dtest=LLMServiceManagerTest

# Teste de conectividade
./mvnw test -Dtest=LLMServiceConfigTest
```

---

## üéØ Casos de Uso Recomendados

| Cen√°rio | Estrat√©gia | Primary | Secondary |
|---------|-----------|---------|-----------|
| **Desenvolvimento** | PRIMARY_ONLY | LM_STUDIO | - |
| **Produ√ß√£o** | FAILOVER | LM_STUDIO | OPENAI |
| **Alta Carga** | ROUND_ROBIN | OLLAMA | LM_STUDIO |
| **Custo Otimizado** | SMART_ROUTING | Local | Cloud |
| **M√°xima Qualidade** | FAILOVER | GPT-4 | Claude |
| **QA/Testing** | DUAL_VERIFICATION | Provider A | Provider B |

---

## ‚úÖ Checklist de Setup

- [ ] Copiar `.env.example` para `.env`
- [ ] Configurar provedor prim√°rio
- [ ] Decidir se precisa de secund√°rio
- [ ] Se sim, configurar provedor secund√°rio e habilitar
- [ ] Escolher estrat√©gia apropriada
- [ ] Configurar API keys (se necess√°rio)
- [ ] Testar conectividade
- [ ] Deploy!

---

## üîê Seguran√ßa

**Importante**: Nunca commite API keys!

```bash
# .gitignore deve conter:
.env
*.env
application-local.properties
```

Use vari√°veis de ambiente:
```properties
llmservice.provider2.api.key=${OPENAI_API_KEY}
```

---

## üìû Suporte

**Problemas?**
1. Consulte `MULTI_LLM_PROVIDER_GUIDE.md`
2. Verifique logs de inicializa√ß√£o
3. Teste health checks
4. Verifique estat√≠sticas

**Logs Esperados**:
```
INFO  MultiLLMServiceConfig - Initializing Primary LLMService
INFO  MultiLLMServiceConfig -   Provider: LM_STUDIO
INFO  MultiLLMServiceConfig - Primary LLMService initialized successfully
INFO  MultiLLMServiceConfig - Initializing Secondary LLMService
INFO  MultiLLMServiceConfig -   Provider: OPENAI
INFO  MultiLLMServiceConfig - Secondary LLMService initialized successfully
INFO  MultiLLMServiceConfig - LLMServiceManager initialized with 2 provider(s)
```

---

**Preparado por**: Claude Code
**Data**: 2025-10-13
**Vers√£o**: 1.0
**Status**: ‚úÖ Pronto para Produ√ß√£o
