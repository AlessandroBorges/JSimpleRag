# An√°lise de Impacto: LLMServiceManager na Refatora√ß√£o de Embeddings

**Data**: 2025-01-25
**Vers√£o**: 1.0
**Status**: An√°lise T√©cnica

---

## üìã Contexto

Ap√≥s revisar os documentos:
- `LLMSERVICE_POOL_ANALYSIS.md`
- `LLMServiceManager.java`
- `MultiLLMServiceConfig.java`

Identifiquei que o sistema JSimpleRag utiliza um **pool de LLMServices** gerenciado pelo `LLMServiceManager`, com roteamento baseado em modelos atrav√©s do m√©todo:

```java
LLMService llmServiceManager.getLLMServiceByRegisteredModel(String modelName)
```

Isso tem **impactos significativos** na proposta de refatora√ß√£o original (`splitting_and_embedding_generation.md`).

---

## üéØ Descobertas Principais

### 1. LLMServiceManager como Pool

**O que √©:**
- Gerenciador de **m√∫ltiplos** LLMService (n√£o apenas um)
- Suporta primary, secondary, tertiary, etc.
- Pool de servi√ßos: `List<LLMService> services`

**Como funciona:**

```java
// N√£o se usa LLMService diretamente
// Mas sim LLMServiceManager que roteia para o LLMService correto

LLMService service = llmServiceManager.getLLMServiceByRegisteredModel("nomic-embed-text");
float[] embedding = service.embeddings(op, text, params);
```

### 2. Roteamento Baseado em Modelo

**M√©todo principal:**

```java
public LLMService getLLMServiceByRegisteredModel(String modelName)
```

**Caracter√≠sticas:**
- Busca no pool qual LLMService tem o modelo registrado
- Retorna o LLMService apropriado
- Retorna `null` se modelo n√£o encontrado
- Matching: exact ‚Üí partial ‚Üí alias

**Exemplo de uso:**

```java
// Buscar service que tenha o modelo de embedding
LLMService embeddingService = llmServiceManager
    .getLLMServiceByRegisteredModel("nomic-embed-text");

if (embeddingService != null) {
    MapParam params = new MapParam().model("nomic-embed-text");
    float[] vector = embeddingService.embeddings(Embeddings_Op.QUERY, text, params);
}
```

### 3. M√∫ltiplas Estrat√©gias de Roteamento

O LLMServiceManager suporta v√°rias estrat√©gias:
- `PRIMARY_ONLY` - usa apenas o primeiro
- `FAILOVER` - failover autom√°tico
- `ROUND_ROBIN` - distribui√ß√£o de carga
- `MODEL_BASED` - roteamento por modelo dispon√≠vel ‚≠ê **RELEVANTE**
- `SMART_ROUTING` - roteamento inteligente
- `DUAL_VERIFICATION` - compara√ß√£o de resultados

**A estrat√©gia MODEL_BASED √© a mais relevante para embeddings!**

### 4. Configura√ß√£o de M√∫ltiplos Providers

```properties
# Primary (LM Studio)
llmservice.provider.name=LM_STUDIO
llmservice.provider.embedding.model=nomic-embed-text
llmservice.provider.llm.models=qwen3-1.7b

# Secondary (Ollama)
llmservice.provider2.enabled=true
llmservice.provider2.name=OLLAMA
llmservice.provider2.embedding.model=mxbai-embed-large
llmservice.provider2.llm.models=mistral

# Strategy
llmservice.strategy=MODEL_BASED
```

---

## ‚ö†Ô∏è Impactos na Proposta Original

### Impacto 1: Inje√ß√£o de Depend√™ncias nas Strategies

**Proposta Original (INCORRETA):**

```java
@Component
public class QueryEmbeddingStrategy implements EmbeddingGenerationStrategy {
    private final LLMService llmService;  // ‚ùå ERRADO

    public QueryEmbeddingStrategy(LLMService llmService) {
        this.llmService = llmService;
    }

    @Override
    public List<DocumentEmbeddingDTO> generate(EmbeddingRequest request) {
        float[] embedding = llmService.embeddings(op, text, params);
    }
}
```

**Proposta Corrigida (CORRETA):**

```java
@Component
public class QueryEmbeddingStrategy implements EmbeddingGenerationStrategy {
    private final LLMServiceManager llmServiceManager;  // ‚úÖ CORRETO

    public QueryEmbeddingStrategy(LLMServiceManager llmServiceManager) {
        this.llmServiceManager = llmServiceManager;
    }

    @Override
    public List<DocumentEmbeddingDTO> generate(EmbeddingRequest request) {
        // Obter o service apropriado para o modelo
        String embeddingModel = request.getEmbeddingModelName();
        LLMService llmService = llmServiceManager
            .getLLMServiceByRegisteredModel(embeddingModel);

        if (llmService == null) {
            throw new IllegalStateException(
                "No LLM service found for embedding model: " + embeddingModel
            );
        }

        MapParam params = new MapParam().model(embeddingModel);
        float[] embedding = llmService.embeddings(op, text, params);
    }
}
```

**Mudan√ßas necess√°rias:**
- ‚úÖ Injetar `LLMServiceManager` ao inv√©s de `LLMService`
- ‚úÖ Usar `getLLMServiceByRegisteredModel(modelName)` para obter service
- ‚úÖ Tratar caso de modelo n√£o encontrado (`null`)
- ‚úÖ Passar `modelName` no `MapParam`

---

### Impacto 2: Modelo de Dados - EmbeddingRequest

**Proposta Original:**

```java
@Data
@Builder
public class EmbeddingRequest {
    private ChapterDTO chapter;
    private String text;
    private LibraryDTO library;
    private Embeddings_Op operation;
    private TipoEmbedding tipoEmbedding;
    private Integer generationFlag;
    // ... outros campos
}
```

**Proposta Corrigida:**

```java
@Data
@Builder
public class EmbeddingRequest {
    private ChapterDTO chapter;
    private String text;
    private LibraryDTO library;
    private Embeddings_Op operation;
    private TipoEmbedding tipoEmbedding;
    private Integer generationFlag;

    // ‚≠ê NOVOS CAMPOS NECESS√ÅRIOS
    /**
     * Nome do modelo de embedding a ser usado.
     * Exemplo: "nomic-embed-text", "text-embedding-ada-002"
     */
    private String embeddingModelName;

    /**
     * Nome do modelo de completion para Q&A e sumariza√ß√£o.
     * Exemplo: "qwen3-1.7b", "gpt-4"
     */
    private String completionModelName;

    // ... outros campos
}
```

**Mudan√ßas necess√°rias:**
- ‚úÖ Adicionar campo `embeddingModelName`
- ‚úÖ Adicionar campo `completionModelName` (para Q&A e sumariza√ß√£o)
- ‚úÖ Esses campos devem ser populados a partir de `LibraryDTO` ou configura√ß√£o global

---

### Impacto 3: Modelo de Dados - LibraryDTO

A `LibraryDTO` deve incluir configura√ß√£o de modelos por biblioteca:

**Proposta:**

```java
@Data
public class LibraryDTO {
    private Integer id;
    private String nome;
    private TipoBiblioteca tipoBiblioteca;
    private String areaConhecimento;
    private Double pesoSemantico;
    private Double pesoTextual;
    private MetaBiblioteca metadados;

    // ‚≠ê NOVOS CAMPOS NECESS√ÅRIOS
    /**
     * Modelo de embedding padr√£o para esta biblioteca.
     * Se null, usa configura√ß√£o global.
     * Exemplo: "nomic-embed-text"
     */
    private String defaultEmbeddingModel;

    /**
     * Modelo de completion padr√£o para esta biblioteca.
     * Se null, usa configura√ß√£o global.
     * Exemplo: "qwen3-1.7b"
     */
    private String defaultCompletionModel;
}
```

**Alternativa: Configura√ß√£o Global**

Se todas as bibliotecas usam os mesmos modelos, podemos usar configura√ß√£o global:

```properties
# Modelo padr√£o para embeddings
rag.embedding.default-model=nomic-embed-text

# Modelo padr√£o para completions (Q&A, sumariza√ß√£o)
rag.completion.default-model=qwen3-1.7b
```

**Decis√£o necess√°ria:**
- Modelos por biblioteca OU modelos globais?
- Ou h√≠brido (global com override por biblioteca)?

---

### Impacto 4: EmbeddingService Interface

**Proposta Original:**

```java
public interface EmbeddingService {
    float[] generateQueryEmbedding(String query, LibraryDTO library);
}
```

**Proposta Corrigida - Op√ß√£o A (passar modelo explicitamente):**

```java
public interface EmbeddingService {
    float[] generateQueryEmbedding(String query, LibraryDTO library, String modelName);
}
```

**Proposta Corrigida - Op√ß√£o B (obter modelo do library):**

```java
public interface EmbeddingService {
    // Usa library.getDefaultEmbeddingModel() internamente
    float[] generateQueryEmbedding(String query, LibraryDTO library);
}
```

**Proposta Corrigida - Op√ß√£o C (sobrecarga de m√©todos):**

```java
public interface EmbeddingService {
    // Usa modelo padr√£o da biblioteca
    float[] generateQueryEmbedding(String query, LibraryDTO library);

    // Permite override do modelo
    float[] generateQueryEmbedding(String query, LibraryDTO library, String modelName);
}
```

**Recomenda√ß√£o: Op√ß√£o C** (flexibilidade + conveni√™ncia)

---

### Impacto 5: EmbeddingServiceImpl

**L√≥gica necess√°ria:**

```java
@Service
public class EmbeddingServiceImpl implements EmbeddingService {

    private final LLMServiceManager llmServiceManager;
    private final List<EmbeddingGenerationStrategy> strategies;

    @Value("${rag.embedding.default-model:nomic-embed-text}")
    private String defaultEmbeddingModel;

    @Value("${rag.completion.default-model:qwen3-1.7b}")
    private String defaultCompletionModel;

    @Override
    public float[] generateQueryEmbedding(String query, LibraryDTO library) {
        String modelName = resolveEmbeddingModel(library);
        return generateQueryEmbedding(query, library, modelName);
    }

    @Override
    public float[] generateQueryEmbedding(String query, LibraryDTO library, String modelName) {
        // Obter LLMService apropriado
        LLMService llmService = llmServiceManager.getLLMServiceByRegisteredModel(modelName);

        if (llmService == null) {
            throw new IllegalStateException(
                "No LLM service found for embedding model: " + modelName
            );
        }

        // Criar request e delegar para strategy
        EmbeddingRequest request = EmbeddingRequest.builder()
            .text(query)
            .library(library)
            .operation(Embeddings_Op.QUERY)
            .embeddingModelName(modelName)
            .build();

        EmbeddingGenerationStrategy strategy = findStrategy(request);

        // Strategy usa o modelName do request para obter LLMService
        // e gera o embedding
        return strategy.generateQueryVector(query, modelName);
    }

    /**
     * Resolve qual modelo de embedding usar.
     * Prioridade: 1) LibraryDTO override, 2) Configura√ß√£o global
     */
    private String resolveEmbeddingModel(LibraryDTO library) {
        if (library.getDefaultEmbeddingModel() != null) {
            return library.getDefaultEmbeddingModel();
        }
        return defaultEmbeddingModel;
    }

    private String resolveCompletionModel(LibraryDTO library) {
        if (library.getDefaultCompletionModel() != null) {
            return library.getDefaultCompletionModel();
        }
        return defaultCompletionModel;
    }
}
```

---

### Impacto 6: Strategies - Padr√£o de Implementa√ß√£o

Todas as strategies seguir√£o este padr√£o:

```java
@Component
public class ChapterEmbeddingStrategy implements EmbeddingGenerationStrategy {

    private static final Logger log = LoggerFactory.getLogger(ChapterEmbeddingStrategy.class);

    private final LLMServiceManager llmServiceManager;
    private final ContentSplitter contentSplitter;

    @Value("${rag.embedding.default-model:nomic-embed-text}")
    private String defaultEmbeddingModel;

    public ChapterEmbeddingStrategy(LLMServiceManager llmServiceManager,
                                   ContentSplitter contentSplitter) {
        this.llmServiceManager = llmServiceManager;
        this.contentSplitter = contentSplitter;
    }

    @Override
    public List<DocumentEmbeddingDTO> generate(EmbeddingRequest request) {
        // 1. Resolver modelo a ser usado
        String modelName = request.getEmbeddingModelName() != null
            ? request.getEmbeddingModelName()
            : defaultEmbeddingModel;

        // 2. Obter LLMService apropriado
        LLMService llmService = llmServiceManager.getLLMServiceByRegisteredModel(modelName);

        if (llmService == null) {
            log.error("No LLM service found for model: {}", modelName);
            throw new IllegalStateException("Embedding model not available: " + modelName);
        }

        log.debug("Using LLMService from provider: {} for model: {}",
                 llmService.getServiceProvider(), modelName);

        // 3. L√≥gica espec√≠fica da strategy
        ChapterDTO chapter = request.getChapter();
        List<DocumentEmbeddingDTO> embeddings = new ArrayList<>();

        // ... l√≥gica de chunking e gera√ß√£o de embeddings

        MapParam params = new MapParam().model(modelName);
        float[] vector = llmService.embeddings(
            request.getOperation(),
            textToEmbed,
            params
        );

        // ... construir DocumentEmbeddingDTO

        return embeddings;
    }

    // ... outros m√©todos
}
```

**Padr√£o comum a todas as strategies:**
1. ‚úÖ Injetar `LLMServiceManager`
2. ‚úÖ Injetar configura√ß√£o de modelo padr√£o (`@Value`)
3. ‚úÖ Resolver modelo: request ‚Üí library ‚Üí default
4. ‚úÖ Obter `LLMService` via `getLLMServiceByRegisteredModel()`
5. ‚úÖ Validar se service existe
6. ‚úÖ Usar `MapParam().model(modelName)` ao chamar embeddings/completion
7. ‚úÖ Log do provider usado

---

### Impacto 7: Q&A e Sumariza√ß√£o

Para Q&A e sumariza√ß√£o, al√©m de embeddings, precisamos de **completions**:

```java
@Component
public class QAEmbeddingStrategy implements EmbeddingGenerationStrategy {

    private final LLMServiceManager llmServiceManager;

    @Value("${rag.completion.default-model:qwen3-1.7b}")
    private String defaultCompletionModel;

    @Value("${rag.embedding.default-model:nomic-embed-text}")
    private String defaultEmbeddingModel;

    @Override
    public List<DocumentEmbeddingDTO> generate(EmbeddingRequest request) {
        // 1. Gerar Q&A pairs usando COMPLETION
        String completionModel = request.getCompletionModelName() != null
            ? request.getCompletionModelName()
            : defaultCompletionModel;

        LLMService completionService = llmServiceManager
            .getLLMServiceByRegisteredModel(completionModel);

        MapParam completionParams = new MapParam().model(completionModel);
        String qaPairsJson = completionService.completion(
            systemPrompt,
            userPrompt,
            completionParams
        ).getText();

        List<QAPair> pairs = parseQAPairs(qaPairsJson);

        // 2. Gerar embeddings dos pares usando EMBEDDING
        String embeddingModel = request.getEmbeddingModelName() != null
            ? request.getEmbeddingModelName()
            : defaultEmbeddingModel;

        LLMService embeddingService = llmServiceManager
            .getLLMServiceByRegisteredModel(embeddingModel);

        List<DocumentEmbeddingDTO> embeddings = new ArrayList<>();
        for (QAPair pair : pairs) {
            MapParam embeddingParams = new MapParam().model(embeddingModel);
            float[] vector = embeddingService.embeddings(
                Embeddings_Op.DOCUMENT,
                pair.getQuestion() + "\n" + pair.getAnswer(),
                embeddingParams
            );

            // ... criar DocumentEmbeddingDTO
        }

        return embeddings;
    }
}
```

**Nota importante:**
- Q&A e Sumariza√ß√£o usam **DOIS modelos diferentes**:
  1. Completion model (para gerar Q&A ou resumo)
  2. Embedding model (para vetorizar o resultado)

---

### Impacto 8: SearchController

**Antes (proposta original):**

```java
@RestController
public class SearchController {
    private final EmbeddingService embeddingService;

    float[] embedding = embeddingService.generateQueryEmbedding(query, library);
}
```

**Agora (correto com modelo):**

```java
@RestController
public class SearchController {
    private final EmbeddingService embeddingService;

    // Op√ß√£o A: Usar modelo padr√£o da biblioteca
    float[] embedding = embeddingService.generateQueryEmbedding(query, library);

    // Op√ß√£o B: Permitir override do modelo na request
    String customModel = request.getEmbeddingModel(); // Se usu√°rio especificou
    float[] embedding = customModel != null
        ? embeddingService.generateQueryEmbedding(query, library, customModel)
        : embeddingService.generateQueryEmbedding(query, library);
}
```

---

### Impacto 9: Configura√ß√£o Global

Precisamos adicionar configura√ß√µes:

```properties
# application.properties

# ============ Default Models ============

# Modelo padr√£o para gera√ß√£o de embeddings
rag.embedding.default-model=nomic-embed-text

# Modelo padr√£o para completions (Q&A, sumariza√ß√£o)
rag.completion.default-model=qwen3-1.7b

# ============ LLM Service Manager ============

# Estrat√©gia de roteamento
llmservice.strategy=MODEL_BASED

# Provider prim√°rio (LM Studio)
llmservice.provider.name=LM_STUDIO
llmservice.provider.api.url=http://localhost:1234/v1
llmservice.provider.embedding.model=nomic-embed-text
llmservice.provider.llm.models=qwen3-1.7b

# Provider secund√°rio (Ollama - opcional)
llmservice.provider2.enabled=false
llmservice.provider2.name=OLLAMA
llmservice.provider2.api.url=http://localhost:11434
llmservice.provider2.embedding.model=mxbai-embed-large
llmservice.provider2.llm.models=mistral
```

---

## üìä Resumo dos Impactos

| Componente | Mudan√ßa Necess√°ria | Prioridade |
|------------|-------------------|------------|
| **EmbeddingRequest** | Adicionar `embeddingModelName` e `completionModelName` | üî¥ ALTA |
| **LibraryDTO** | Adicionar `defaultEmbeddingModel` e `defaultCompletionModel` (opcional) | üü° M√âDIA |
| **EmbeddingService** | M√©todos com sobrecarga para aceitar modelName | üî¥ ALTA |
| **EmbeddingServiceImpl** | L√≥gica de resolu√ß√£o de modelo + uso de LLMServiceManager | üî¥ ALTA |
| **Todas as Strategies** | Injetar `LLMServiceManager` + usar `getLLMServiceByRegisteredModel()` | üî¥ ALTA |
| **SearchController** | Passar modelo ao gerar query embedding (opcional override) | üü° M√âDIA |
| **application.properties** | Configurar modelos padr√£o (`rag.embedding.default-model`) | üî¥ ALTA |
| **Entity Library** | Adicionar colunas `default_embedding_model` e `default_completion_model` | üü¢ BAIXA |
| **Liquibase migration** | Adicionar colunas na tabela `library` | üü¢ BAIXA |

---

## ‚úÖ Decis√µes Arquiteturais Necess√°rias

### Decis√£o 1: Configura√ß√£o de Modelos

**Op√ß√£o A: Global apenas**

```properties
rag.embedding.default-model=nomic-embed-text
rag.completion.default-model=qwen3-1.7b
```

**Op√ß√£o B: Por biblioteca (com fallback global)**

```java
// Library entity
private String defaultEmbeddingModel;  // null = usa global
private String defaultCompletionModel; // null = usa global
```

**Op√ß√£o C: H√≠brida (recomendado)**
- Configura√ß√£o global como padr√£o
- Override opcional por biblioteca
- Prioridade: request ‚Üí library ‚Üí global

**Recomenda√ß√£o:** Op√ß√£o C

---

### Decis√£o 2: API do EmbeddingService

**Op√ß√£o A: Sempre passar modelo**

```java
float[] generateQueryEmbedding(String query, LibraryDTO library, String modelName);
```

**Op√ß√£o B: Modelo opcional (sobrecarga)**

```java
float[] generateQueryEmbedding(String query, LibraryDTO library);
float[] generateQueryEmbedding(String query, LibraryDTO library, String modelName);
```

**Recomenda√ß√£o:** Op√ß√£o B (conveni√™ncia + flexibilidade)

---

### Decis√£o 3: Tratamento de Modelo N√£o Encontrado

**Op√ß√£o A: Lan√ßar exce√ß√£o imediatamente**

```java
LLMService service = manager.getLLMServiceByRegisteredModel(model);
if (service == null) {
    throw new IllegalStateException("Model not found: " + model);
}
```

**Op√ß√£o B: Fallback para modelo padr√£o**

```java
LLMService service = manager.getLLMServiceByRegisteredModel(model);
if (service == null) {
    log.warn("Model {} not found, falling back to default", model);
    service = manager.getLLMServiceByRegisteredModel(defaultModel);
}
```

**Op√ß√£o C: Fallback para primary service**

```java
LLMService service = manager.getLLMServiceByRegisteredModel(model);
if (service == null) {
    log.warn("Model {} not found, using primary service", model);
    service = manager.getPrimaryService();
}
```

**Recomenda√ß√£o:** Op√ß√£o A (fail-fast, mais claro para debugging)

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Revisar este documento** com o time
2. ‚úÖ **Tomar decis√µes arquiteturais** (Decis√µes 1, 2, 3)
3. ‚úÖ **Atualizar documento principal** (`splitting_and_embedding_generation.md`)
4. ‚úÖ **Aprovar estrat√©gia completa**
5. ‚úÖ **Iniciar implementa√ß√£o**

---

## üìù Conclus√£o

O uso de `LLMServiceManager` com pool de servi√ßos **N√ÉO invalida a proposta de refatora√ß√£o**, mas requer ajustes importantes:

**‚úÖ Mant√©m-se:**
- Separa√ß√£o de responsabilidades (splitter vs embedding)
- Strategy pattern para tipos de embedding
- EmbeddingService como API p√∫blica
- EmbeddingOrchestrator para coordena√ß√£o ass√≠ncrona

**üîÑ Modifica√ß√µes necess√°rias:**
- Inje√ß√£o de `LLMServiceManager` ao inv√©s de `LLMService`
- Adi√ß√£o de `embeddingModelName` e `completionModelName` em requests
- L√≥gica de resolu√ß√£o de modelo (request ‚Üí library ‚Üí global)
- Uso de `getLLMServiceByRegisteredModel()` em todas as strategies
- Configura√ß√£o de modelos padr√£o em `application.properties`

A arquitetura proposta **continua v√°lida e necess√°ria**, apenas com ajustes para integra√ß√£o adequada com o pool de LLMServices.
