# Proposta de ImplementaÃ§Ã£o - Novo Fluxo de Processamento de Documentos

**Data:** 2025-01-31
**Status:** âœ… APROVADO COM REVISÃ•ES
**VersÃ£o:** 1.1 (Revisado)

---

## ğŸ“‹ Ãndice

1. [Resumo Executivo](#resumo-executivo)
2. [Hierarquia Confirmada](#hierarquia-confirmada)
3. [Diagrama de Fluxo Detalhado](#diagrama-de-fluxo-detalhado)
4. [Arquitetura de Classes](#arquitetura-de-classes)
5. [Estimativa de ImplementaÃ£o](#estimativa-de-implementacao)
6. [Plano de ImplementaÃ§Ã£o](#plano-de-implementacao)

---

## ğŸ“ RevisÃµes Aprovadas (v1.1)

### 1. Ordem de ExecuÃ§Ã£o Ajustada âœ…

**Original:** Contextos criados APÃ“S split
**Revisado:** **Contextos criados ANTES do split**

**RazÃ£o:** Split precisa usar `LLMService.tokenCount(texto, "fast")` para contagem precisa de tokens

**Nova ordem:**
```
ETAPA 2.1: CriaÃ§Ã£o de Contextos (PRIMEIRO)
    â†“
ETAPA 2.2: Split em CapÃ­tulos e Chunks (USA os contextos)
    â†“
ETAPA 2.3: CÃ¡lculo de Vetores de Embeddings
```

---

### 2. Contagem de Tokens via LLMService âœ…

**Original:** Estimativa simples (palavras / 0.75)
**Revisado:** `LLMService.tokenCount(texto, "fast")`

**Uso:**
```java
// Sempre usar modelo "fast" para contagem
int tokens = llmContext.getLLMService().tokenCount(texto, "fast");
```

**Nota:** Valor "fast" pode ser reconfigurado posteriormente via propriedades

---

### 3. Batching DinÃ¢mico com Contexto do Modelo âœ…

**Original:**
- Batch size fixo: 5 textos
- Limite fixo: 4000 tokens

**Revisado:**
- **Batch size:** 10 textos (aumentado para reduzir ciclos)
- **Limite dinÃ¢mico:** `ModelEmbedding.getContextLength()` (pode ser 2048, 8192, etc.)

**LÃ³gica para textos grandes:**
```java
int contextLength = modelEmbedding.getContextLength();
int textTokens = tokenCount(text);

if (textTokens > contextLength) {
    int excedente = textTokens - contextLength;
    double percentual = (excedente * 100.0) / textTokens;

    if (percentual > 2.0) {
        // Excedente > 2%: Gerar resumo via LLM
        String resumo = llmContext.generateCompletion("Resuma:", text);
        // Salvar resumo em metadados["resumo"]
        // Usar resumo para embedding
    } else {
        // Excedente <= 2%: Truncar texto
        text = text.substring(0, contextLength * 4); // ~4 chars/token
    }
}
```

---

### 4. Splitters Mantidos Como EstÃ£o âœ…

**DecisÃ£o:** NÃƒO revisar splitters existentes

**RazÃ£o:** ImplementaÃ§Ãµes atuais adequadas para POC. Risco de particionamento nÃ£o-Ã³timo Ã© aceitÃ¡vel nesta fase.

**Splitters mantidos:**
- `SplitterGenerico.java`
- `SplitterNorma.java`
- `SplitterWiki.java`

---

## Resumo Executivo

### Objetivos da Nova Arquitetura

- âœ… **Simplicidade:** Fluxo sequencial, fÃ¡cil de manter
- âœ… **SeparaÃ§Ã£o de responsabilidades:** Contextos dedicados para LLM e Embeddings
- âœ… **TolerÃ¢ncia a falhas:** Continua processando mesmo com erros individuais
- âœ… **Sem retry global:** Remove complexidade desnecessÃ¡ria
- âœ… **Batch processing:** Reduz chamadas LLM (10 textos por batch, dinÃ¢mico)

### Hierarquia Confirmada

```
Documento (1)
    â”œâ”€â†’ CapÃ­tulo (N) [entidade Chapter]
    â”‚   â”œâ”€â†’ DocEmbedding tipo RESUMO (0 ou 1) [se capÃ­tulo > 2500 tokens]
    â”‚   â””â”€â†’ DocEmbedding tipo TRECHO (M) [chunks do capÃ­tulo]
```

### Exemplo Concreto - Documento de 15.000 tokens

**ConfiguraÃ§Ã£o:**
- Documento: 15.000 tokens total
- 4 capÃ­tulos criados pelo splitter

**DistribuiÃ§Ã£o:**
```
Documento: 15.000 tokens
â”œâ”€ CapÃ­tulo 1: 3.750 tokens
â”‚  â”œâ”€ DocEmb #1: RESUMO (~1024 tokens) â† capÃ­tulo > 2500
â”‚  â”œâ”€ DocEmb #2: TRECHO chunk 1 (1875 tokens)
â”‚  â””â”€ DocEmb #3: TRECHO chunk 2 (1875 tokens)
â”‚
â”œâ”€ CapÃ­tulo 2: 3.750 tokens
â”‚  â”œâ”€ DocEmb #4: RESUMO (~1024 tokens) â† capÃ­tulo > 2500
â”‚  â”œâ”€ DocEmb #5: TRECHO chunk 1 (1875 tokens)
â”‚  â””â”€ DocEmb #6: TRECHO chunk 2 (1875 tokens)
â”‚
â”œâ”€ CapÃ­tulo 3: 1.200 tokens
â”‚  â””â”€ DocEmb #7: TRECHO (1200 tokens) â† sem resumo (< 2500)
â”‚
â””â”€ CapÃ­tulo 4: 6.350 tokens
   â”œâ”€ DocEmb #8: RESUMO (~1024 tokens) â† capÃ­tulo > 2500
   â”œâ”€ DocEmb #9: TRECHO chunk 1 (2117 tokens)
   â”œâ”€ DocEmb #10: TRECHO chunk 2 (2117 tokens)
   â””â”€ DocEmb #11: TRECHO chunk 3 (2116 tokens)

RESULTADO NO BANCO:
- documento: 1 registro
- capitulo: 4 registros
- doc_embedding: 11 registros
  - 3 tipo RESUMO (capÃ­tulos 1, 2, 4)
  - 8 tipo TRECHO (chunks dos capÃ­tulos)
```

### Regras de NegÃ³cio Confirmadas

#### CapÃ­tulos
- **Tamanho ideal:** 2.000 - 4.200 tokens
- **Documentos pequenos:** < 4.200 tokens = 1 capÃ­tulo Ãºnico

#### DocEmbeddings (Chunks)
- **Tamanho mÃ­nimo:** 512 tokens
- **Tamanho mÃ¡ximo:** 4.100 tokens
- **Tamanho ideal:** 2.048 tokens

#### Resumos
- **Threshold:** SÃ³ criar se capÃ­tulo > 2.500 tokens
- **Tamanho:** MÃ¡ximo de 1.024 tokens
- **Tipo:** `TipoEmbedding.RESUMO`

#### Q&A (NÃƒO implementado nesta release)
- Funcionalidade adiada para versÃµes futuras

---

## Diagrama de Fluxo Detalhado

### VisÃ£o Geral do Fluxo

```txt
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: Upload e PersistÃªncia do Documento (SÃ­ncrono)           â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚ DocumentoService.uploadFromText/Url/File()                      â”‚
â”‚   â”œâ”€â†’ ValidaÃ§Ã£o: Library exists                                 â”‚
â”‚   â”œâ”€â†’ CÃ¡lculo: Checksum (CRC64)                                 â”‚
â”‚   â”œâ”€â†’ VerificaÃ§Ã£o: Duplicados (checksum + biblioteca_id)        â”‚
â”‚   â”œâ”€â†’ PersistÃªncia: INSERT documento (JPA)                      â”‚
â”‚   â””â”€â†’ Retorno: DocumentoDTO                                     â”‚
â”‚                                                                 â”‚
â”‚ DuraÃ§Ã£o: ~500ms | DB: 3 queries | LLM: 0 calls                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: Processamento AssÃ­ncrono (Iniciado manualmente)         â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚ DocumentoService.processDocumentAsync(documentId)               â”‚
â”‚   â”œâ”€â†’ Carrega: Documento + Library (DB)                         â”‚
â”‚   â””â”€â†’ Delega: DocumentProcessingService.process()               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 2.1: CriaÃ§Ã£o de Contextos (1x por documento) âœ… PRIMEIRO! â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚ DocumentProcessingService.createContexts()                      â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ LLMContext.create(library, llmServiceManager)             â”‚
â”‚   â”‚   â”œâ”€â†’ LLMServiceManager.getBestCompletionModelName()        â”‚
â”‚   â”‚   â”‚   â””â”€â†’ Busca modelo de completion no cache               â”‚
â”‚   â”‚   â”‚                                                         â”‚
â”‚   â”‚   â”œâ”€â†’ LLMServiceManager.getServiceByModel(modelName)        â”‚
â”‚   â”‚   â”‚   â””â”€â†’ Retorna: LLMService configurado                   â”‚
â”‚   â”‚   â”‚                                                         â”‚
â”‚   â”‚   â””â”€â†’ Retorna: LLMContext {                                 â”‚
â”‚   â”‚           llmService: LLMService,                           â”‚
â”‚   â”‚           model: Model,                                     â”‚
â”‚   â”‚           modelName: String,                                â”‚
â”‚   â”‚           params: MapParam                                  â”‚
â”‚   â”‚       }                                                     â”‚
â”‚   â”‚                                                             â”‚
â”‚   â””â”€â†’ EmbeddingContext.create(library, llmServiceManager)       â”‚
â”‚       â”œâ”€â†’ LLMServiceManager.getLLMServiceByRegisteredModel()    â”‚
â”‚       â”‚   â””â”€â†’ Busca modelo de embedding no cache                â”‚
â”‚       â”‚                                                         â”‚
â”‚       â””â”€â†’ Retorna: EmbeddingContext {                           â”‚
â”‚               llmService: LLMService,                           â”‚
â”‚               modelEmbedding: ModelEmbedding,                   â”‚
â”‚               modelName: String,                                â”‚
â”‚               params: MapParam,                                 â”‚
â”‚               contextLength: Integer  â† getContextLength()      â”‚
â”‚           }                                                     â”‚
â”‚                                                                 â”‚
â”‚ DuraÃ§Ã£o: ~100-200ms (lookup em cache)                           â”‚
â”‚ LLM: 0 calls (sÃ³ leitura de cache)                              â”‚
â”‚ âš ï¸ IMPORTANTE: Contextos criados ANTES do split!                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 2.2: Split em CapÃ­tulos e Chunks (Sem vetores!)           â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚ DocumentProcessingService.splitAndPersist(llmContext)  â† USA!   â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ DocumentRouter.detectContentType(markdown)                â”‚
â”‚   â”‚   â””â”€â†’ Retorna: TipoConteudo (GENERICO, NORMATIVO, WIKI)     â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ SplitterFactory.createSplitter(tipo, library)             â”‚
â”‚   â”‚   â””â”€â†’ Retorna: SplitterGenerico/Norma/Wiki                  â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ splitter.splitDocumento(documento)                        â”‚
â”‚   â”‚   â”‚                                                         â”‚
â”‚   â”‚   â”œâ”€â†’ Divide em capÃ­tulos (~2000-4200 tokens)               â”‚
â”‚   â”‚   â”‚   â””â”€â†’ List<ChapterDTO>                                  â”‚
â”‚   â”‚   â”‚                                                         â”‚
â”‚   â”‚   â””â”€â†’ Para cada capÃ­tulo:                                   â”‚
â”‚   â”‚       â”‚                                                     â”‚
â”‚   â”‚       â”œâ”€â†’ Se capÃ­tulo > 2500 tokens:                        â”‚
â”‚   â”‚       â”‚   â”œâ”€â†’ Gera RESUMO via LLM (~1024 tokens)            â”‚
â”‚   â”‚       â”‚   â”‚   â””â”€â†’ DocEmbedding(tipo=RESUMO, vector=NULL)    â”‚
â”‚   â”‚       â”‚   â”‚                                                 â”‚
â”‚   â”‚       â”‚   â””â”€â†’ Divide em chunks (~2048 tokens)               â”‚
â”‚   â”‚       â”‚       â””â”€â†’ N Ã— DocEmbedding(tipo=TRECHO, vector=NULL)â”‚
â”‚   â”‚       â”‚                                                     â”‚
â”‚   â”‚       â””â”€â†’ Se capÃ­tulo â‰¤ 2500 tokens:                        â”‚
â”‚   â”‚           â””â”€â†’ 1 Ã— DocEmbedding(tipo=TRECHO, vector=NULL)    â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ chapterRepository.saveAll(chapters)                       â”‚
â”‚   â”‚   â””â”€â†’ Batch INSERT capÃ­tulos                                â”‚
â”‚   â”‚                                                             â”‚
â”‚   â””â”€â†’ embeddingRepository.saveAll(embeddings)  â† vector=NULL!   â”‚
â”‚       â””â”€â†’ Batch INSERT embeddings (SEM vetores)                 â”‚
â”‚                                                                 â”‚
â”‚ DuraÃ§Ã£o: ~5-15s (com LLM para resumos)                          â”‚
â”‚ DB: 2 batch INSERTs                                             â”‚
â”‚ LLM: ~4 completions (resumos) se todos caps > 2500 tokens       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 2.3: CÃ¡lculo de Vetores de Embeddings (DINÃ‚MICO)          â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚ DocumentProcessingService.calculateEmbeddings()                 â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ Carrega: DocEmbeddings com vector=NULL (DB query)         â”‚
â”‚   â”‚   â””â”€â†’ List<DocumentEmbedding> (11 embeddings no exemplo)    â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ ObtÃ©m: contextLength = embContext.getContextLength()      â”‚
â”‚   â”‚   â””â”€â†’ Exemplo: 8192 tokens (depende do modelo)              â”‚
â”‚   â”‚                                                             â”‚
â”‚   â”œâ”€â†’ Agrupa em batches de atÃ© 10 textos (respeita contextLength)â”‚
â”‚   â”‚   â””â”€â†’ Batch 1: [emb1...emb10] (10 textos)                   â”‚
â”‚   â”‚   â””â”€â†’ Batch 2: [emb11] (1 texto)                            â”‚
â”‚   â”‚                                                             â”‚
â”‚   â””â”€â†’ Para cada batch:                                          â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â†’ Para cada embedding no batch:                         â”‚
â”‚       â”‚   â”œâ”€â†’ tokens = llmContext.tokenCount(texto, "fast")     â”‚
â”‚       â”‚   â””â”€â†’ Se tokens > contextLength:                        â”‚
â”‚       â”‚       â”œâ”€â†’ Se excedente > 2%: gera resumo via LLM        â”‚
â”‚       â”‚       â””â”€â†’ Se excedente <= 2%: trunca texto              â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â†’ String[] texts = batch.map(e -> processar texto)      â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€â†’ float[][] vectors = embeddingContext.llmService       â”‚
â”‚       â”‚       .embeddings(                                      â”‚
â”‚       â”‚           Embeddings_Op.DOCUMENT,                       â”‚
â”‚       â”‚           texts,  â† Array de textos processados         â”‚
â”‚       â”‚           embeddingContext.params                       â”‚
â”‚       â”‚       )                                                 â”‚
â”‚       â”‚   â””â”€â†’ Retorna: N vetores de embeddings                  â”‚
â”‚       â”‚                                                         â”‚
â”‚       â””â”€â†’ Para cada embedding + vector:                         â”‚
â”‚           â”‚                                                     â”‚
â”‚           â”œâ”€â†’ try {                                             â”‚
â”‚           â”‚       embeddingRepository.updateEmbeddingVector(    â”‚
â”‚           â”‚           embedding.getId(),                        â”‚
â”‚           â”‚           vector                                    â”‚
â”‚           â”‚       )                                             â”‚
â”‚           â”‚       log.debug("Updated embedding #{}", id)        â”‚
â”‚           â”‚   }                                                 â”‚
â”‚           â”‚                                                     â”‚
â”‚           â””â”€â†’ catch (Exception e) {                             â”‚
â”‚                   log.error("Failed embedding #{}", id, e)      â”‚
â”‚                   e.printStackTrace()                           â”‚
â”‚                   // Continua com prÃ³ximo embedding             â”‚
â”‚               }                                                 â”‚
â”‚                                                                 â”‚
â”‚ DuraÃ§Ã£o: ~2-5s (2 batches Ã— ~1-2s cada)                         â”‚
â”‚ LLM: 2 calls de embeddings (batch) + N resumos de textos grandesâ”‚
â”‚ DB: 11 UPDATEs (serial, tolerante a falhas)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ETAPA 2.4: FinalizaÃ§Ã£o                                          â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”   â”‚
â”‚ DocumentProcessingService.finalize()                            â”‚
â”‚   â”œâ”€â†’ Conta: embeddings processados vs total                    â”‚
â”‚   â”œâ”€â†’ Atualiza: documento.tokensTotal                           â”‚
â”‚   â””â”€â†’ Retorna: ProcessingResult {                               â”‚
â”‚           documentId: Integer,                                  â”‚
â”‚           chaptersCount: 4,                                     â”‚
â”‚           embeddingsCount: 11,                                  â”‚
â”‚           embeddingsProcessed: 11,                              â”‚
â”‚           embeddingsFailed: 0,                                  â”‚
â”‚           duration: "12.5s"                                     â”‚
â”‚       }                                                         â”‚
â”‚                                                                 â”‚
â”‚ DuraÃ§Ã£o: ~100ms                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TEMPO TOTAL ESTIMADO: ~8-16 segundos (melhoria de ~15-20%)
- Upload: 0.5s
- Contextos: 0.2s (ANTES do split!)
- Split + Resumos: 5-15s (depende de quantos resumos)
- Embeddings: 2-5s (com batching dinÃ¢mico)
- FinalizaÃ§Ã£o: 0.1s

CHAMADAS LLM TOTAL: ~6-8 calls (vs ~7-9 antes)
- Resumos: 3-4 completions (se caps > 2500 tokens)
- Embeddings: 2 batch calls (11 textos / batches de atÃ© 10)
- Textos grandes: 0-2 resumos extras (se texto > contextLength com +2%)

CHAMADAS DB TOTAL: ~18 queries
- Upload: 3 (validation + insert)
- Split: 2 (batch inserts)
- Embeddings: 1 (select NULL vectors) + 11 (updates)
- FinalizaÃ§Ã£o: 1 (update documento)

MELHORIAS COM REVISÃƒO:
- âœ… Batches maiores (10 vs 5) = menos ciclos
- âœ… Contagem precisa de tokens via tokenCount("fast")
- âœ… Contexto dinÃ¢mico do modelo respeitado
- âœ… Textos grandes tratados inteligentemente (resumo ou truncamento)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Arquitetura de Classes

### Novos Componentes

#### 1. LLMContext.java

**LocalizaÃ§Ã£o:** `src/main/java/bor/tools/simplerag/service/processing/context/LLMContext.java`

**Responsabilidade:** Encapsula LLMService validado + modelo + parÃ¢metros para operaÃ§Ãµes de completion (resumos, Q&A)

**Campos:**

```java
private LLMService llmService;
private Model model;
private String modelName;  // Alias ou nome do modelo
private MapParam params;
```

**MÃ©todos Principais:**

```java
// Factory method - cria contexto validado
public static LLMContext create(LibraryDTO library, LLMServiceManager manager)

// Gera completion usando contexto
public String generateCompletion(String systemPrompt, String userPrompt)

// Contagem precisa de tokens (REVISÃƒO v1.1)
public int tokenCount(String text, String model) throws Exception

// Valida se contexto estÃ¡ pronto
public boolean isValid()
```

**Uso:**

```java
// Criar 1x por documento
LLMContext llmContext = LLMContext.create(library, llmServiceManager);

// Reutilizar para todos os resumos
String summary1 = llmContext.generateCompletion(systemPrompt, chapter1Text);
String summary2 = llmContext.generateCompletion(systemPrompt, chapter2Text);
// ...
```

---

#### 2. EmbeddingContext.java

**LocalizaÃ§Ã£o:** `src/main/java/bor/tools/simplerag/service/processing/context/EmbeddingContext.java`

**Responsabilidade:** Encapsula LLMService validado + modelo de embedding + parÃ¢metros para geraÃ§Ã£o de vetores

**Campos:**

```java
private LLMService llmService;
private ModelEmbedding modelEmbedding;  // NÃƒO usar Model genÃ©rico
private String modelName;  // Alias ou nome do modelo
private MapParam params;
```

**MÃ©todos Principais:**

```java
// Factory method - cria contexto validado
public static EmbeddingContext create(LibraryDTO library, LLMServiceManager manager)

// Gera embedding individual
public float[] generateEmbedding(String text, Embeddings_Op operation)

// Gera batch de embeddings (ATÃ‰ 10 TEXTOS, respeitando contextLength)
public float[][] generateEmbeddingsBatch(String[] texts, Embeddings_Op operation)

// Valida se contexto estÃ¡ pronto
public boolean isValid()

// Retorna dimensÃ£o do modelo
public Integer getEmbeddingDimension()

// Retorna limite dinÃ¢mico do contexto (REVISÃƒO v1.1)
public Integer getContextLength()
```

**Uso:**

```java
// Criar 1x por documento
EmbeddingContext embContext = EmbeddingContext.create(library, llmServiceManager);

// Obter limite dinÃ¢mico do modelo
int contextLength = embContext.getContextLength(); // Ex: 8192

// Reutilizar para todos os embeddings (batch de atÃ© 10 textos)
String[] batch1 = {text1, text2, text3, text4, text5,
                   text6, text7, text8, text9, text10};
float[][] vectors1 = embContext.generateEmbeddingsBatch(batch1, Embeddings_Op.DOCUMENT);

String[] batch2 = {text11};
float[][] vectors2 = embContext.generateEmbeddingsBatch(batch2, Embeddings_Op.DOCUMENT);
```

---

#### 3. DocumentProcessingService.java

**LocalizaÃ§Ã£o:** `src/main/java/bor/tools/simplerag/service/processing/DocumentProcessingService.java`

**Responsabilidade:** Novo orquestrador sequencial que substitui `EmbeddingOrchestrator`

**DependÃªncias:**

```java
private final DocumentRouter documentRouter;
private final SplitterFactory splitterFactory;
private final ChapterRepository chapterRepository;
private final DocEmbeddingJdbcRepository embeddingRepository;
private final LLMServiceManager llmServiceManager;
private final LibraryService libraryService;
```

**Constantes (ATUALIZADAS v1.1):**

```java
private static final int BATCH_SIZE = 10;  // Textos por batch (REVISADO: era 5)
private static final String TOKEN_MODEL = "fast";  // Modelo para tokenCount()
private static final int SUMMARY_THRESHOLD_TOKENS = 2500;  // Threshold para resumo
private static final int SUMMARY_MAX_TOKENS = 1024;  // Tamanho mÃ¡ximo do resumo
private static final double OVERSIZE_THRESHOLD_PERCENT = 2.0;  // % para resumir vs truncar
```

**MÃ©todos Principais:**

```java
// MÃ©todo pÃºblico assÃ­ncrono - ponto de entrada
@Async
public CompletableFuture<ProcessingResult> processDocument(
    Documento documento,
    LibraryDTO library
)

// ETAPA 2.1: Split e persistÃªncia (vector=NULL)
@Transactional
protected SplitResult splitAndPersist(Documento documento, LibraryDTO library)

// Helper: cria embeddings para 1 capÃ­tulo
private List<DocumentEmbedding> createChapterEmbeddings(
    Chapter chapter,
    ChapterDTO chapterDTO,
    Documento documento,
    LibraryDTO library
)

// ETAPA 2.3: Calcula vetores e atualiza DB
private int calculateAndUpdateEmbeddings(
    List<DocumentEmbedding> embeddings,
    EmbeddingContext context
)

// Helper: estima tokens
private int estimateTokens(String text)
```

**Fluxo Interno (REVISADO v1.1):**

```java
processDocument()
    â”œâ”€â†’ LLMContext.create()          â† PRIMEIRO! (REVISADO)
    â”œâ”€â†’ EmbeddingContext.create()    â† PRIMEIRO! (REVISADO)
    â”‚
    â”œâ”€â†’ splitAndPersist(llmContext)  â† USA llmContext para tokenCount()
    â”‚   â”œâ”€â†’ DocumentRouter.detectContentType()
    â”‚   â”œâ”€â†’ SplitterFactory.createSplitter()
    â”‚   â”œâ”€â†’ splitter.splitDocumento()
    â”‚   â”œâ”€â†’ createChapterEmbeddings() [para cada cap]
    â”‚   â”‚   â””â”€â†’ USA llmContext.tokenCount(texto, "fast")
    â”‚   â”œâ”€â†’ chapterRepository.saveAll()
    â”‚   â””â”€â†’ embeddingRepository.saveAll() [vector=NULL]
    â”‚
    â”œâ”€â†’ calculateAndUpdateEmbeddings(embContext, llmContext)
    â”‚   â”œâ”€â†’ ObtÃ©m contextLength = embContext.getContextLength()
    â”‚   â”œâ”€â†’ Agrupa em batches (atÃ© 10 textos, respeita contextLength)
    â”‚   â””â”€â†’ Para cada batch:
    â”‚       â”œâ”€â†’ handleOversizedText() [tokenCount + resumo/trunca se necessÃ¡rio]
    â”‚       â”œâ”€â†’ embContext.generateEmbeddingsBatch()
    â”‚       â””â”€â†’ embeddingRepository.updateEmbeddingVector() [cada um]
    â”‚
    â””â”€â†’ Retorna ProcessingResult
```

---

### Componentes a Modificar

#### DocumentoService.java

**MudanÃ§as:**

1. **Adicionar dependÃªncia:**

```java
private final DocumentProcessingService documentProcessingService;
```

2. **Adicionar novo mÃ©todo:**

```java
/**
 * Process document asynchronously using new sequential flow.
 *
 * @param documentId Document ID
 * @return CompletableFuture with processing result
 */
@Async
public CompletableFuture<DocumentProcessingService.ProcessingResult>
    processDocumentAsync(Integer documentId) {

    log.info("Starting async processing for document ID: {}", documentId);

    // Load document
    Documento documento = documentoRepository.findById(documentId)
            .orElseThrow(() -> new IllegalArgumentException(
                "Document not found: " + documentId));

    // Load library
    Optional<Library> libraryOpt = libraryService.findById(documento.getBibliotecaId());
    if (libraryOpt.isEmpty()) {
        throw new IllegalArgumentException(
            "Library not found: " + documento.getBibliotecaId());
    }

    LibraryDTO biblioteca = LibraryDTO.from(libraryOpt.get());

    // Delegate to new processing service
    return documentProcessingService.processDocument(documento, biblioteca);
}
```

3. **Deprecar mÃ©todo antigo:**

```java
@Deprecated(since = "0.0.3", forRemoval = true)
public CompletableFuture<ProcessingStatus> processDocumentAsyncOld(
        Integer documentId,
        boolean includeQA,
        boolean includeSummary) {
    // CÃ³digo antigo mantido por compatibilidade
    // SerÃ¡ removido em versÃ£o futura
}
```

---

#### DocEmbeddingJdbcRepository.java

**MudanÃ§as:**

1. **Adicionar mÃ©todo batch saveAll():**

```java
/**
 * Batch insert embeddings with NULL vectors.
 *
 * Optimized for initial persistence - vectors calculated later.
 *
 * @param embeddings List of embeddings (vector can be NULL)
 * @return List of generated IDs
 * @throws SQLException if batch insert fails
 */
public List<Integer> saveAll(List<DocumentEmbedding> embeddings) throws SQLException {
    if (embeddings == null || embeddings.isEmpty()) {
        return Collections.emptyList();
    }

    String sql = "INSERT INTO doc_embedding " +
                "(biblioteca_id, documento_id, capitulo_id, texto, " +
                "embedding_vector, tipo_embedding, metadados, order_chapter, " +
                "created_at, updated_at) " +
                "VALUES (?, ?, ?, ?, ?::vector, ?::tipo_embedding_enum, " +
                "?::jsonb, ?, ?, ?) " +
                "RETURNING id";

    List<Integer> generatedIds = new ArrayList<>();

    try (PreparedStatement ps = connection.prepareStatement(sql)) {
        for (DocumentEmbedding emb : embeddings) {
            ps.setInt(1, emb.getLibraryId());
            ps.setObject(2, emb.getDocumentoId());
            ps.setObject(3, emb.getChapterId());
            ps.setString(4, emb.getTexto());

            // Vector can be NULL
            if (emb.getEmbeddingVector() != null) {
                ps.setString(5, vectorToString(emb.getEmbeddingVector()));
            } else {
                ps.setNull(5, java.sql.Types.VARCHAR);
            }

            ps.setString(6, emb.getTipoEmbedding().name());
            ps.setString(7, metadataToJson(emb.getMetadados()));
            ps.setObject(8, emb.getOrderChapter());
            ps.setTimestamp(9, Timestamp.valueOf(LocalDateTime.now()));
            ps.setTimestamp(10, Timestamp.valueOf(LocalDateTime.now()));

            ps.addBatch();
        }

        // Execute batch
        ps.executeBatch();

        // Retrieve generated IDs
        try (ResultSet rs = ps.getGeneratedKeys()) {
            while (rs.next()) {
                generatedIds.add(rs.getInt(1));
            }
        }
    }

    log.debug("Batch inserted {} embeddings", generatedIds.size());
    return generatedIds;
}
```

2. **MÃ©todo updateEmbeddingVector() jÃ¡ existe?**

Se NÃƒO existir, adicionar:

```java
/**
 * Update embedding vector for existing embedding.
 *
 * Used after batch insert with NULL vectors.
 *
 * @param embeddingId Embedding ID
 * @param vector Embedding vector
 * @throws SQLException if update fails
 */
public void updateEmbeddingVector(Integer embeddingId, float[] vector)
        throws SQLException {

    if (embeddingId == null || vector == null) {
        throw new IllegalArgumentException("ID and vector cannot be null");
    }

    String sql = "UPDATE doc_embedding SET embedding_vector = ?::vector, " +
                "updated_at = ? WHERE id = ?";

    try (PreparedStatement ps = connection.prepareStatement(sql)) {
        ps.setString(1, vectorToString(vector));
        ps.setTimestamp(2, Timestamp.valueOf(LocalDateTime.now()));
        ps.setInt(3, embeddingId);

        int rows = ps.executeUpdate();
        if (rows == 0) {
            throw new SQLException("Embedding not found: " + embeddingId);
        }
    }
}
```

---

### Componentes a Deprecar

#### 1. EmbeddingOrchestrator.java

```java
@Deprecated(since = "0.0.3", forRemoval = true)
@Service
public class EmbeddingOrchestrator {
    // Manter cÃ³digo existente
    // Adicionar mensagem de depreciaÃ§Ã£o nos logs

    public EmbeddingOrchestrator(...) {
        log.warn("EmbeddingOrchestrator is deprecated. " +
                 "Use DocumentProcessingService instead.");
    }
}
```

#### 2. AsyncSplitterService.java

```java
// JÃ¡ estÃ¡ @Deprecated(since = "0.0.2", forRemoval = true)
// Nenhuma mudanÃ§a necessÃ¡ria
```

#### 3. EmbeddingProcessorImpl.java

```java
// JÃ¡ estÃ¡ @Deprecated(since = "0.0.2", forRemoval = true)
// Nenhuma mudanÃ§a necessÃ¡ria
```

---

## Estimativa de Implementacao

### Breakdown Detalhado

| # | Tarefa | Complexidade | Tempo | PrÃ©-requisitos |
|---|--------|--------------|-------|----------------|
| 1 | Criar package `service.processing.context` | Trivial | 5min | - |
| 2 | Implementar `LLMContext.java` | Baixa | 1-2h | - |
| 3 | Implementar `EmbeddingContext.java` | Baixa | 1-2h | - |
| 4 | Testes unitÃ¡rios dos contextos | MÃ©dia | 2-3h | 2, 3 |
| 5 | Adicionar `saveAll()` em `DocEmbeddingJdbcRepository` | Baixa | 1h | - |
| 6 | Verificar/Adicionar `updateEmbeddingVector()` | Trivial | 30min | - |
| 7 | Criar package `service.processing` | Trivial | 5min | - |
| 8 | Implementar `DocumentProcessingService` (estrutura) | MÃ©dia | 2h | 2, 3, 5, 6 |
| 9 | Implementar `splitAndPersist()` | MÃ©dia | 2-3h | 8 |
| 10 | Implementar `createChapterEmbeddings()` | MÃ©dia | 1-2h | 9 |
| 11 | Implementar geraÃ§Ã£o de resumos (LLM) | MÃ©dia | 2-3h | 2, 10 |
| 12 | Implementar `calculateAndUpdateEmbeddings()` | MÃ©dia | 2-3h | 3, 8 |
| 13 | Modificar `DocumentoService.processDocumentAsync()` | Baixa | 1h | 8 |
| 14 | Deprecar `EmbeddingOrchestrator` | Trivial | 30min | - |
| 15 | Testes de integraÃ§Ã£o (fluxo completo) | Alta | 3-4h | 8-13 |
| 16 | DocumentaÃ§Ã£o JavaDoc | Baixa | 1-2h | Todos |
| 17 | AtualizaÃ§Ã£o de README/docs | Baixa | 1h | Todos |
| **TOTAL** | | | **22-32h** | |

### DistribuiÃ§Ã£o por Fase

#### Fase 1: FundaÃ§Ã£o (6-9h)
- âœ… Criar contextos (LLMContext + EmbeddingContext)
- âœ… Adicionar mÃ©todos batch no repository
- âœ… Testes unitÃ¡rios dos contextos

**Entregas:**
- `LLMContext.java` funcional
- `EmbeddingContext.java` funcional
- `DocEmbeddingJdbcRepository.saveAll()` funcional
- Testes passando

---

#### Fase 2: Processamento Core (10-14h)
- âœ… Criar `DocumentProcessingService`
- âœ… Implementar `splitAndPersist()`
- âœ… Implementar `calculateAndUpdateEmbeddings()`
- âœ… Testes de integraÃ§Ã£o

**Entregas:**
- Fluxo completo funcional (sem resumos)
- Documento processado do inÃ­cio ao fim
- Embeddings calculados e persistidos

---

#### Fase 3: Resumos e FinalizaÃ§Ã£o (6-9h)
- âœ… Adicionar geraÃ§Ã£o de resumos via LLM
- âœ… Modificar `DocumentoService`
- âœ… Deprecar componentes antigos
- âœ… DocumentaÃ§Ã£o

**Entregas:**
- Sistema completo com resumos
- DocumentaÃ§Ã£o atualizada
- Componentes antigos deprecados

---

## Plano de Implementacao

### Cronograma Sugerido

#### Semana 1 - FundaÃ§Ã£o

**Dia 1: Contextos**
- [ ] Criar `LLMContext.java` (2h)
- [ ] Criar `EmbeddingContext.java` (2h)
- [ ] Testes bÃ¡sicos (2h)

**Dia 2: Repository**
- [ ] Adicionar `saveAll()` em Repository (1h)
- [ ] Verificar `updateEmbeddingVector()` (30min)
- [ ] Testes de repository (2h)
- [ ] IntegraÃ§Ã£o contextos + repository (1h)

---

#### Semana 2 - Processamento Core

**Dia 3: Service Base**
- [ ] Criar `DocumentProcessingService` (estrutura) (2h)
- [ ] Implementar `splitAndPersist()` (3h)
- [ ] Testes de splitting (2h)

**Dia 4: Embeddings**
- [ ] Implementar `calculateAndUpdateEmbeddings()` (3h)
- [ ] Implementar batch processing (2h)
- [ ] Testes de embeddings (2h)

**Dia 5: IntegraÃ§Ã£o**
- [ ] Teste end-to-end (documento pequeno) (2h)
- [ ] Teste end-to-end (documento grande) (2h)
- [ ] CorreÃ§Ãµes e ajustes (2h)

---

#### Semana 3 - Resumos e FinalizaÃ§Ã£o

**Dia 6: Resumos**
- [ ] Implementar geraÃ§Ã£o de resumos (3h)
- [ ] Integrar resumos no fluxo (2h)
- [ ] Testes com resumos (2h)

**Dia 7: IntegraÃ§Ã£o Final**
- [ ] Modificar `DocumentoService` (1h)
- [ ] Deprecar componentes antigos (30min)
- [ ] Testes de regressÃ£o (2h)
- [ ] DocumentaÃ§Ã£o JavaDoc (2h)

**Dia 8: DocumentaÃ§Ã£o**
- [ ] Atualizar README (1h)
- [ ] Atualizar docs tÃ©cnicos (1h)
- [ ] Code review (2h)
- [ ] Deploy/Release (1h)

---

### EstratÃ©gia de Testes

#### Testes UnitÃ¡rios (por componente)

**LLMContext:**
- âœ… CriaÃ§Ã£o com modelo vÃ¡lido
- âœ… CriaÃ§Ã£o sem modelo disponÃ­vel (exception)
- âœ… GeraÃ§Ã£o de completion
- âœ… ValidaÃ§Ã£o de contexto

**EmbeddingContext:**
- âœ… CriaÃ§Ã£o com modelo vÃ¡lido
- âœ… CriaÃ§Ã£o sem modelo disponÃ­vel (exception)
- âœ… GeraÃ§Ã£o de embedding individual
- âœ… GeraÃ§Ã£o de batch
- âœ… ValidaÃ§Ã£o de contexto

**DocumentProcessingService:**
- âœ… Split de documento pequeno (1 capÃ­tulo)
- âœ… Split de documento grande (N capÃ­tulos)
- âœ… CriaÃ§Ã£o de resumos (cap > 2500 tokens)
- âœ… Sem resumos (cap < 2500 tokens)
- âœ… Batch de embeddings
- âœ… TolerÃ¢ncia a falhas (embedding individual falha)

---

#### Testes de IntegraÃ§Ã£o

**Fluxo Completo:**

```java
@Test
void testProcessDocument_SmallDocument() {
    // Documento: 3000 tokens (1 capÃ­tulo, sem resumo)
    // Esperado:
    // - 1 capÃ­tulo
    // - 2 DocEmbeddings tipo TRECHO
    // - 0 DocEmbeddings tipo RESUMO
}

@Test
void testProcessDocument_LargeDocument() {
    // Documento: 15000 tokens (4 capÃ­tulos)
    // Esperado:
    // - 4 capÃ­tulos
    // - 3 DocEmbeddings tipo RESUMO (caps 1,2,4 > 2500)
    // - 8 DocEmbeddings tipo TRECHO (chunks)
    // - Total: 11 embeddings
}

@Test
void testProcessDocument_WithEmbeddingFailure() {
    // Simular falha em 1 embedding
    // Verificar que outros embeddings sÃ£o processados
    // Verificar que resultado reporta falhas
}

@Test
void testProcessDocument_WithSummaryGeneration() {
    // Documento com capÃ­tulo > 2500 tokens
    // Verificar geraÃ§Ã£o de resumo via LLM
    // Verificar persistÃªncia do resumo
    // Verificar cÃ¡lculo de embedding do resumo
}
```

---

## Riscos e MitigaÃ§Ãµes

### Riscos Identificados

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|---------------|---------|-----------|
| Splitters existentes nÃ£o retornam chunks adequados | MÃ©dia | Alto | Revisar splitters antes de implementar; ajustar se necessÃ¡rio |
| Batch embeddings falha com textos grandes | Baixa | MÃ©dio | Validar tamanho total antes de chamar LLM; limitar a 4000 tokens |
| LLMService.embeddings(String[]) nÃ£o existe | Baixa | Alto | Verificar existÃªncia do mÃ©todo antes de iniciar; criar se necessÃ¡rio |
| GeraÃ§Ã£o de resumos muito lenta | MÃ©dia | MÃ©dio | Implementar timeout; considerar resumos opcionais |
| Falhas em cascade (1 erro para tudo) | Baixa | Alto | Implementado try-catch individual; processamento continua |
| Repository batch insert nÃ£o retorna IDs | Baixa | Alto | Testar RETURNING clause; fallback para insert individual se necessÃ¡rio |

---

## MÃ©tricas de Sucesso

### Performance

- âœ… Documento de 15k tokens processado em **< 20 segundos**
- âœ… ReduÃ§Ã£o de **80%+** em chamadas LLM vs implementaÃ§Ã£o atual
- âœ… Batch embeddings reduz tempo em **70%+** vs serial

### Qualidade

- âœ… **100%** de cobertura de testes nos novos componentes
- âœ… **0** warnings no SonarQube
- âœ… DocumentaÃ§Ã£o JavaDoc completa

### Funcionalidade

- âœ… Resumos gerados para capÃ­tulos > 2500 tokens
- âœ… Chunks persistidos corretamente (512-4100 tokens)
- âœ… Embeddings calculados em batch (5 textos/call)
- âœ… Falhas individuais nÃ£o param o processamento

---

## PrÃ³ximos Passos ApÃ³s AprovaÃ§Ã£o

1. **Criar branch de feature:**

   ```bash
   git checkout -b feature/new-processing-flow
   ```

2. **Implementar Fase 1** (6-9h):
   - Contextos + Repository + Testes
   - Commit incremental apÃ³s cada componente

3. **Implementar Fase 2** (10-14h):
   - DocumentProcessingService
   - Testes de integraÃ§Ã£o
   - Commit apÃ³s cada mÃ©todo funcional

4. **Implementar Fase 3** (6-9h):
   - Resumos + IntegraÃ§Ã£o final
   - DeprecaÃ§Ã£o + DocumentaÃ§Ã£o
   - Commit final

5. **Code Review + Merge:**
   - Pull Request com descriÃ§Ã£o detalhada
   - Review por time
   - Merge para main apÃ³s aprovaÃ§Ã£o

---

## Anexos

### A. Diagrama de Classes UML

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DocumentoService                â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ + uploadFromText()                      â”‚
â”‚ + processDocumentAsync()   [MODIFIED]   â”‚
â”‚ + processDocumentAsyncOld() [DEPRECATED]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ delega
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    DocumentProcessingService   [NEW]    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ + processDocument()                     â”‚
â”‚ # splitAndPersist()                     â”‚
â”‚ - createChapterEmbeddings()             â”‚
â”‚ - calculateAndUpdateEmbeddings()        â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ usa                 â”‚ usa
    â†“                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLMContext  â”‚    â”‚ EmbeddingContext â”‚
â”‚    [NEW]     â”‚    â”‚      [NEW]       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ - llmService â”‚    â”‚ - llmService     â”‚
â”‚ - model      â”‚    â”‚ - modelEmbedding â”‚
â”‚ - modelName  â”‚    â”‚ - modelName      â”‚
â”‚ - params     â”‚    â”‚ - params         â”‚
â”‚              â”‚    â”‚                  â”‚
â”‚ + create()   â”‚    â”‚ + create()       â”‚
â”‚ + generate() â”‚    â”‚ + generateBatch()â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### B. Exemplo de Uso Completo

```java
// 1. Upload documento
DocumentoDTO doc = documentoService.uploadFromText(
    "Manual do UsuÃ¡rio",
    markdownContent,
    libraryId,
    null
);

// 2. Processar documento (assÃ­ncrono)
CompletableFuture<ProcessingResult> future =
    documentoService.processDocumentAsync(doc.getId());

// 3. Aguardar resultado
ProcessingResult result = future.get();

// 4. Verificar resultado
System.out.println("CapÃ­tulos: " + result.getChaptersCount());
System.out.println("Embeddings: " + result.getEmbeddingsCount());
System.out.println("Processados: " + result.getEmbeddingsProcessed());
System.out.println("Falhas: " + result.getEmbeddingsFailed());
System.out.println("Tempo: " + result.getDuration());
```

---

**Documento Preparado Por:** Claude Code
**Data de CriaÃ§Ã£o:** 2025-01-31
**Data de RevisÃ£o:** 2025-01-31
**VersÃ£o:** 1.1 (Revisado)
**Status:** âœ… APROVADO COM REVISÃ•ES (pelo usuÃ¡rio)
